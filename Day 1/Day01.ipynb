{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataStorm02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJH5cTea2sTU"
      },
      "source": [
        "import pandas as pd  \r\n",
        "import numpy as np   \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "sns.set()\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "from imblearn.over_sampling import SMOTE\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from tensorflow.keras.layers import  Dropout, Dense\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from sklearn.metrics import confusion_matrix, f1_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tqRyblxEWWC"
      },
      "source": [
        "train = pd.read_csv(\"/content/train.csv\")\r\n",
        "valid = pd.read_csv(\"/content/validation.csv\")\r\n",
        "test = pd.read_csv(\"/content/test.csv\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "_LzggdhDEiUJ",
        "outputId": "88c3085b-2d1f-40f7-e69e-193361a9a6a0"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Educational_Level</th>\n",
              "      <th>Income</th>\n",
              "      <th>Adults</th>\n",
              "      <th>Children</th>\n",
              "      <th>Babies</th>\n",
              "      <th>Meal_Type</th>\n",
              "      <th>Visted_Previously</th>\n",
              "      <th>Previous_Cancellations</th>\n",
              "      <th>Required_Car_Parking</th>\n",
              "      <th>Use_Promotion</th>\n",
              "      <th>Discount_Rate</th>\n",
              "      <th>Room_Rate</th>\n",
              "      <th>is_female</th>\n",
              "      <th>Is_Latino</th>\n",
              "      <th>Is_caucasian</th>\n",
              "      <th>Is_African American</th>\n",
              "      <th>Is_Asian American</th>\n",
              "      <th>East</th>\n",
              "      <th>North</th>\n",
              "      <th>South</th>\n",
              "      <th>West</th>\n",
              "      <th>Airport Hotels</th>\n",
              "      <th>City Hotel</th>\n",
              "      <th>Resort</th>\n",
              "      <th>Deposit_type</th>\n",
              "      <th>Agent</th>\n",
              "      <th>Online</th>\n",
              "      <th>Direct</th>\n",
              "      <th>Total_People</th>\n",
              "      <th>Rooms_Needed</th>\n",
              "      <th>Total_Days_Staying</th>\n",
              "      <th>Total_Room_Rate</th>\n",
              "      <th>Days_since_Booking</th>\n",
              "      <th>WeekDay</th>\n",
              "      <th>Staying_in_Weekend</th>\n",
              "      <th>Checkin_Year</th>\n",
              "      <th>Checkin_Month</th>\n",
              "      <th>Reservation_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>116.10</td>\n",
              "      <td>224.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>97.50</td>\n",
              "      <td>168.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>85.50</td>\n",
              "      <td>160.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>181.00</td>\n",
              "      <td>124.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>153.75</td>\n",
              "      <td>190.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age  Educational_Level  ...  Checkin_Month  Reservation_Status\n",
              "0  18.0                1.0  ...            5.0                   0\n",
              "1  18.0                2.0  ...            4.0                   0\n",
              "2  18.0                3.0  ...            4.0                   0\n",
              "3  18.0                3.0  ...            3.0                   0\n",
              "4  18.0                3.0  ...            7.0                   0\n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "KM3xKmkmErre",
        "outputId": "28fcdc63-edb4-4bda-9cbe-ea4d97d7bf4c"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Educational_Level</th>\n",
              "      <th>Income</th>\n",
              "      <th>Adults</th>\n",
              "      <th>Children</th>\n",
              "      <th>Babies</th>\n",
              "      <th>Meal_Type</th>\n",
              "      <th>Visted_Previously</th>\n",
              "      <th>Previous_Cancellations</th>\n",
              "      <th>Required_Car_Parking</th>\n",
              "      <th>Use_Promotion</th>\n",
              "      <th>Discount_Rate</th>\n",
              "      <th>Room_Rate</th>\n",
              "      <th>is_female</th>\n",
              "      <th>Is_Latino</th>\n",
              "      <th>Is_caucasian</th>\n",
              "      <th>Is_African American</th>\n",
              "      <th>Is_Asian American</th>\n",
              "      <th>East</th>\n",
              "      <th>North</th>\n",
              "      <th>South</th>\n",
              "      <th>West</th>\n",
              "      <th>Airport Hotels</th>\n",
              "      <th>City Hotel</th>\n",
              "      <th>Resort</th>\n",
              "      <th>Deposit_type</th>\n",
              "      <th>Agent</th>\n",
              "      <th>Online</th>\n",
              "      <th>Direct</th>\n",
              "      <th>Total_People</th>\n",
              "      <th>Rooms_Needed</th>\n",
              "      <th>Total_Days_Staying</th>\n",
              "      <th>Total_Room_Rate</th>\n",
              "      <th>Days_since_Booking</th>\n",
              "      <th>WeekDay</th>\n",
              "      <th>Staying_in_Weekend</th>\n",
              "      <th>Checkin_Year</th>\n",
              "      <th>Checkin_Month</th>\n",
              "      <th>Reservation_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "      <td>63720.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>43.909660</td>\n",
              "      <td>2.596388</td>\n",
              "      <td>2.291329</td>\n",
              "      <td>2.334338</td>\n",
              "      <td>1.752136</td>\n",
              "      <td>0.354478</td>\n",
              "      <td>1.845223</td>\n",
              "      <td>0.329283</td>\n",
              "      <td>0.110572</td>\n",
              "      <td>0.718168</td>\n",
              "      <td>0.756538</td>\n",
              "      <td>12.150706</td>\n",
              "      <td>175.223785</td>\n",
              "      <td>0.501297</td>\n",
              "      <td>0.249500</td>\n",
              "      <td>0.249562</td>\n",
              "      <td>0.255763</td>\n",
              "      <td>0.245175</td>\n",
              "      <td>0.195699</td>\n",
              "      <td>0.210259</td>\n",
              "      <td>0.398148</td>\n",
              "      <td>0.195894</td>\n",
              "      <td>0.333628</td>\n",
              "      <td>0.329655</td>\n",
              "      <td>0.336717</td>\n",
              "      <td>1.573749</td>\n",
              "      <td>0.141716</td>\n",
              "      <td>0.564072</td>\n",
              "      <td>0.294213</td>\n",
              "      <td>4.086475</td>\n",
              "      <td>1.158315</td>\n",
              "      <td>1.825276</td>\n",
              "      <td>323.776490</td>\n",
              "      <td>109.402408</td>\n",
              "      <td>3.984906</td>\n",
              "      <td>0.534857</td>\n",
              "      <td>2015.811357</td>\n",
              "      <td>6.164318</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.561583</td>\n",
              "      <td>0.916019</td>\n",
              "      <td>0.927993</td>\n",
              "      <td>1.077412</td>\n",
              "      <td>0.653896</td>\n",
              "      <td>0.515187</td>\n",
              "      <td>0.728839</td>\n",
              "      <td>0.423747</td>\n",
              "      <td>0.282352</td>\n",
              "      <td>0.405027</td>\n",
              "      <td>0.404418</td>\n",
              "      <td>10.621907</td>\n",
              "      <td>43.434664</td>\n",
              "      <td>0.450371</td>\n",
              "      <td>0.389949</td>\n",
              "      <td>0.390245</td>\n",
              "      <td>0.393242</td>\n",
              "      <td>0.387555</td>\n",
              "      <td>0.356695</td>\n",
              "      <td>0.366564</td>\n",
              "      <td>0.441168</td>\n",
              "      <td>0.357411</td>\n",
              "      <td>0.425087</td>\n",
              "      <td>0.423412</td>\n",
              "      <td>0.424715</td>\n",
              "      <td>0.772543</td>\n",
              "      <td>0.314747</td>\n",
              "      <td>0.446510</td>\n",
              "      <td>0.410091</td>\n",
              "      <td>1.265060</td>\n",
              "      <td>0.340699</td>\n",
              "      <td>0.960620</td>\n",
              "      <td>229.839207</td>\n",
              "      <td>69.922872</td>\n",
              "      <td>1.818991</td>\n",
              "      <td>0.454469</td>\n",
              "      <td>0.569493</td>\n",
              "      <td>2.954645</td>\n",
              "      <td>0.816503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>-4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2014.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>31.367196</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.528489</td>\n",
              "      <td>1.665715</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.364160</td>\n",
              "      <td>0.555299</td>\n",
              "      <td>3.720915</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>163.099654</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>2.486891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2015.266894</td>\n",
              "      <td>3.964892</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>44.000000</td>\n",
              "      <td>2.999684</td>\n",
              "      <td>2.052790</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.946175</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>175.290137</td>\n",
              "      <td>0.501703</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120946</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.727207</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.503479</td>\n",
              "      <td>244.000000</td>\n",
              "      <td>105.431044</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.638076</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>6.020210</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>56.336245</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.786994</td>\n",
              "      <td>2.403695</td>\n",
              "      <td>0.819300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>213.971229</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.498439</td>\n",
              "      <td>0.497531</td>\n",
              "      <td>0.528172</td>\n",
              "      <td>0.473417</td>\n",
              "      <td>0.201447</td>\n",
              "      <td>0.289761</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.198096</td>\n",
              "      <td>0.833619</td>\n",
              "      <td>0.818465</td>\n",
              "      <td>0.836946</td>\n",
              "      <td>2.049456</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.688092</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.495425</td>\n",
              "      <td>417.152548</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>5.409526</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>8.086343</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1992.000000</td>\n",
              "      <td>708.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Age  Educational_Level  ...  Checkin_Month  Reservation_Status\n",
              "count  63720.000000       63720.000000  ...   63720.000000        63720.000000\n",
              "mean      43.909660           2.596388  ...       6.164318            1.000000\n",
              "std       14.561583           0.916019  ...       2.954645            0.816503\n",
              "min       18.000000           1.000000  ...       1.000000            0.000000\n",
              "25%       31.367196           2.000000  ...       3.964892            0.000000\n",
              "50%       44.000000           2.999684  ...       6.020210            1.000000\n",
              "75%       56.336245           3.000000  ...       8.086343            2.000000\n",
              "max       70.000000           4.000000  ...      12.000000            2.000000\n",
              "\n",
              "[8 rows x 39 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM43cKR7Fvtb",
        "outputId": "7cb4f6a1-fe02-4114-89d5-d7143c00c475"
      },
      "source": [
        "train.Reservation_Status.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    21240\n",
              "1     4134\n",
              "2     2125\n",
              "Name: Reservation_Status, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONX3fFoYF_8o",
        "outputId": "5f4e9166-7faa-4e9e-e2a7-63bed79c724a"
      },
      "source": [
        "valid.Reservation_Status.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1610\n",
              "1     741\n",
              "2     398\n",
              "Name: Reservation_Status, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgHZ_1GAE60f"
      },
      "source": [
        "drop_cols = ['Is_Latino', 'East', 'Expected_checkin','Expected_checkout', 'Booking_date', 'Total_People', 'Resort', 'Agent', 'Use_Promotion', 'Room_Rate', 'Rooms_Needed']\r\n",
        "train.drop(drop_cols, axis=1, inplace=True)\r\n",
        "valid.drop(drop_cols, axis=1, inplace=True)\r\n",
        "test.drop(drop_cols, axis=1, inplace=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5s3rAgnGW2w"
      },
      "source": [
        "X_train = train.drop('Reservation_Status',axis=1)\r\n",
        "y_train = train.Reservation_Status\r\n",
        "X_valid = valid.drop('Reservation_Status',axis=1)\r\n",
        "y_valid = valid.Reservation_Status\r\n",
        "\r\n",
        "columns = X_train.columns"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Fr4kbbVrS0"
      },
      "source": [
        "scaler = MinMaxScaler()\r\n",
        "X_train = scaler.fit_transform(X_train)\r\n",
        "X_valid = scaler.transform(X_valid)\r\n",
        "X_test = scaler.transform(test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIpExNskGreO"
      },
      "source": [
        "sm = SMOTE(random_state=1, sampling_strategy={0:21250,1:10000,2:7000}) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC5etqQsFXEP"
      },
      "source": [
        "X_train, y_train = sm.fit_sample(X_train, y_train)\r\n",
        "X_train = pd.DataFrame(X_train, columns=columns)\r\n",
        "y_train = pd.DataFrame(y_train, columns=['Reservation_Status'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xskKrx9ZJddp"
      },
      "source": [
        "# X_valid, y_valid = sm.fit_sample(X_valid, y_valid)\r\n",
        "# X_valid = pd.DataFrame(X_valid, columns=columns)\r\n",
        "# y_valid = pd.DataFrame(y_valid, columns=['Reservation_Status'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP_IuD-7HhN9",
        "outputId": "03a8c6ab-f85b-447c-8f28-eb44b86ac394"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Reservation_Status\n",
              "0                     21250\n",
              "1                     10000\n",
              "2                      7000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDIfpO0zJHwr",
        "outputId": "fef3ab27-257b-4c44-ae38-1e00740c31e8"
      },
      "source": [
        "y_valid.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1610\n",
              "1     741\n",
              "2     398\n",
              "Name: Reservation_Status, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALjDdzy9X14E",
        "outputId": "7c466ade-bacc-49ab-ebd3-50e6a523f825"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(63720, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctjM3vLcX5QH",
        "outputId": "ed2016f8-904a-47e8-bc7b-59c49eac0d7b"
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2749, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpu05OJ6fbF_",
        "outputId": "8b92742f-40a3-4f3f-c12d-1e9c7379c126"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4318, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSfXrdZtL4ML"
      },
      "source": [
        "# X_train[\"Reservation_Status\"] = y_train\r\n",
        "# X_valid[\"Reservation_Status\"] = y_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KZndNReWMSAt",
        "outputId": "05ce3e92-0217-4fea-d0ae-13fb04be855f"
      },
      "source": [
        "# X_train.to_csv('train.csv', index=False)      \r\n",
        "# files.download('train.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_84b6888e-9e10-4267-b8f5-4d44ffda49a8\", \"train.csv\", 20836752)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4du8_L3YMo0D",
        "outputId": "eba3d6e8-c76a-4e6a-8485-ad760e135c51"
      },
      "source": [
        "# X_valid.to_csv('validation.csv', index=False)      \r\n",
        "# files.download('validation.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e4f0feb0-da56-473d-9e17-3ff4853d7393\", \"validation.csv\", 1375923)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvz2aK-YNAST"
      },
      "source": [
        "#model building\r\n",
        "model = Sequential([\r\n",
        "    Dense(units=64, activation='relu'),\r\n",
        "    Dense(units=32, activation='relu'),\r\n",
        "    Dense(units=16, activation='relu'),\r\n",
        "    Dense(units=3, activation='softmax'),\r\n",
        "])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB07PRlKYobQ",
        "outputId": "3129a663-a6c2-4b8e-8853-c2cba5380802"
      },
      "source": [
        "model.compile(optimizer='Adam', metrics = ['accuracy'], loss='sparse_categorical_crossentropy', )\r\n",
        "history = model.fit(x=X_train, y=y_train, batch_size=128, epochs=120, verbose=1, validation_data=(X_valid, y_valid),)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "299/299 [==============================] - 1s 3ms/step - loss: 0.9932 - accuracy: 0.5318 - val_loss: 0.9972 - val_accuracy: 0.5406\n",
            "Epoch 2/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.9384 - accuracy: 0.5583 - val_loss: 0.9895 - val_accuracy: 0.5558\n",
            "Epoch 3/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.9219 - accuracy: 0.5693 - val_loss: 0.9945 - val_accuracy: 0.5515\n",
            "Epoch 4/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.9158 - accuracy: 0.5718 - val_loss: 1.0103 - val_accuracy: 0.5406\n",
            "Epoch 5/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8977 - accuracy: 0.5837 - val_loss: 1.0287 - val_accuracy: 0.4878\n",
            "Epoch 6/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8924 - accuracy: 0.5816 - val_loss: 1.0446 - val_accuracy: 0.4744\n",
            "Epoch 7/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8772 - accuracy: 0.5949 - val_loss: 1.0462 - val_accuracy: 0.5035\n",
            "Epoch 8/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8750 - accuracy: 0.5980 - val_loss: 1.0609 - val_accuracy: 0.5220\n",
            "Epoch 9/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8520 - accuracy: 0.6105 - val_loss: 1.0574 - val_accuracy: 0.4965\n",
            "Epoch 10/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8420 - accuracy: 0.6168 - val_loss: 1.0603 - val_accuracy: 0.4918\n",
            "Epoch 11/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8359 - accuracy: 0.6191 - val_loss: 1.0812 - val_accuracy: 0.5180\n",
            "Epoch 12/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8282 - accuracy: 0.6241 - val_loss: 1.0885 - val_accuracy: 0.5238\n",
            "Epoch 13/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8149 - accuracy: 0.6329 - val_loss: 1.1075 - val_accuracy: 0.4762\n",
            "Epoch 14/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8086 - accuracy: 0.6377 - val_loss: 1.0902 - val_accuracy: 0.5016\n",
            "Epoch 15/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.8012 - accuracy: 0.6454 - val_loss: 1.1033 - val_accuracy: 0.4729\n",
            "Epoch 16/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7912 - accuracy: 0.6501 - val_loss: 1.1017 - val_accuracy: 0.5184\n",
            "Epoch 17/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7930 - accuracy: 0.6430 - val_loss: 1.1169 - val_accuracy: 0.4987\n",
            "Epoch 18/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7765 - accuracy: 0.6584 - val_loss: 1.1229 - val_accuracy: 0.4915\n",
            "Epoch 19/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7758 - accuracy: 0.6547 - val_loss: 1.1337 - val_accuracy: 0.5136\n",
            "Epoch 20/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7757 - accuracy: 0.6547 - val_loss: 1.1535 - val_accuracy: 0.4809\n",
            "Epoch 21/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7696 - accuracy: 0.6577 - val_loss: 1.1191 - val_accuracy: 0.4955\n",
            "Epoch 22/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7639 - accuracy: 0.6610 - val_loss: 1.1319 - val_accuracy: 0.5049\n",
            "Epoch 23/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7547 - accuracy: 0.6689 - val_loss: 1.1487 - val_accuracy: 0.4809\n",
            "Epoch 24/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7560 - accuracy: 0.6655 - val_loss: 1.1609 - val_accuracy: 0.4478\n",
            "Epoch 25/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7524 - accuracy: 0.6722 - val_loss: 1.1688 - val_accuracy: 0.4751\n",
            "Epoch 26/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7464 - accuracy: 0.6742 - val_loss: 1.1469 - val_accuracy: 0.4929\n",
            "Epoch 27/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7412 - accuracy: 0.6748 - val_loss: 1.1729 - val_accuracy: 0.4944\n",
            "Epoch 28/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7378 - accuracy: 0.6783 - val_loss: 1.1693 - val_accuracy: 0.4911\n",
            "Epoch 29/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7328 - accuracy: 0.6790 - val_loss: 1.1900 - val_accuracy: 0.5315\n",
            "Epoch 30/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7316 - accuracy: 0.6808 - val_loss: 1.1723 - val_accuracy: 0.4711\n",
            "Epoch 31/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7321 - accuracy: 0.6802 - val_loss: 1.1691 - val_accuracy: 0.4984\n",
            "Epoch 32/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7269 - accuracy: 0.6821 - val_loss: 1.1831 - val_accuracy: 0.4827\n",
            "Epoch 33/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7198 - accuracy: 0.6856 - val_loss: 1.1835 - val_accuracy: 0.4849\n",
            "Epoch 34/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7192 - accuracy: 0.6850 - val_loss: 1.1955 - val_accuracy: 0.4711\n",
            "Epoch 35/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7153 - accuracy: 0.6865 - val_loss: 1.2161 - val_accuracy: 0.5169\n",
            "Epoch 36/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7169 - accuracy: 0.6900 - val_loss: 1.2045 - val_accuracy: 0.5031\n",
            "Epoch 37/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7119 - accuracy: 0.6892 - val_loss: 1.2127 - val_accuracy: 0.5096\n",
            "Epoch 38/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7065 - accuracy: 0.6920 - val_loss: 1.2118 - val_accuracy: 0.5009\n",
            "Epoch 39/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7081 - accuracy: 0.6948 - val_loss: 1.2347 - val_accuracy: 0.4678\n",
            "Epoch 40/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7038 - accuracy: 0.6938 - val_loss: 1.2387 - val_accuracy: 0.4831\n",
            "Epoch 41/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7010 - accuracy: 0.6987 - val_loss: 1.2305 - val_accuracy: 0.4962\n",
            "Epoch 42/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7048 - accuracy: 0.6939 - val_loss: 1.2201 - val_accuracy: 0.4747\n",
            "Epoch 43/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.7012 - accuracy: 0.6959 - val_loss: 1.2468 - val_accuracy: 0.4664\n",
            "Epoch 44/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.7000 - val_loss: 1.2361 - val_accuracy: 0.4969\n",
            "Epoch 45/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.6988 - val_loss: 1.2458 - val_accuracy: 0.4751\n",
            "Epoch 46/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6958 - accuracy: 0.6958 - val_loss: 1.2480 - val_accuracy: 0.5122\n",
            "Epoch 47/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.7026 - val_loss: 1.2409 - val_accuracy: 0.4820\n",
            "Epoch 48/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6887 - accuracy: 0.7018 - val_loss: 1.2482 - val_accuracy: 0.4834\n",
            "Epoch 49/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.7056 - val_loss: 1.2624 - val_accuracy: 0.4627\n",
            "Epoch 50/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6833 - accuracy: 0.7057 - val_loss: 1.2776 - val_accuracy: 0.5045\n",
            "Epoch 51/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.7002 - val_loss: 1.2776 - val_accuracy: 0.4904\n",
            "Epoch 52/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6782 - accuracy: 0.7059 - val_loss: 1.2507 - val_accuracy: 0.5158\n",
            "Epoch 53/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6783 - accuracy: 0.7030 - val_loss: 1.2692 - val_accuracy: 0.4980\n",
            "Epoch 54/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6735 - accuracy: 0.7064 - val_loss: 1.2813 - val_accuracy: 0.5078\n",
            "Epoch 55/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6777 - accuracy: 0.7090 - val_loss: 1.2895 - val_accuracy: 0.5064\n",
            "Epoch 56/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6687 - accuracy: 0.7098 - val_loss: 1.2740 - val_accuracy: 0.4805\n",
            "Epoch 57/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6681 - accuracy: 0.7121 - val_loss: 1.2705 - val_accuracy: 0.4904\n",
            "Epoch 58/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6731 - accuracy: 0.7111 - val_loss: 1.2814 - val_accuracy: 0.4718\n",
            "Epoch 59/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6673 - accuracy: 0.7113 - val_loss: 1.2873 - val_accuracy: 0.4729\n",
            "Epoch 60/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6622 - accuracy: 0.7142 - val_loss: 1.2670 - val_accuracy: 0.4940\n",
            "Epoch 61/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6578 - accuracy: 0.7165 - val_loss: 1.2915 - val_accuracy: 0.5049\n",
            "Epoch 62/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6651 - accuracy: 0.7130 - val_loss: 1.3007 - val_accuracy: 0.4911\n",
            "Epoch 63/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6691 - accuracy: 0.7122 - val_loss: 1.2915 - val_accuracy: 0.4878\n",
            "Epoch 64/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6566 - accuracy: 0.7185 - val_loss: 1.3148 - val_accuracy: 0.5238\n",
            "Epoch 65/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6595 - accuracy: 0.7170 - val_loss: 1.2984 - val_accuracy: 0.5089\n",
            "Epoch 66/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6599 - accuracy: 0.7138 - val_loss: 1.3174 - val_accuracy: 0.4565\n",
            "Epoch 67/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6545 - accuracy: 0.7186 - val_loss: 1.3222 - val_accuracy: 0.4653\n",
            "Epoch 68/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6461 - accuracy: 0.7245 - val_loss: 1.3292 - val_accuracy: 0.4460\n",
            "Epoch 69/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6488 - accuracy: 0.7222 - val_loss: 1.3308 - val_accuracy: 0.5140\n",
            "Epoch 70/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6519 - accuracy: 0.7217 - val_loss: 1.3132 - val_accuracy: 0.4765\n",
            "Epoch 71/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6507 - accuracy: 0.7197 - val_loss: 1.3167 - val_accuracy: 0.4594\n",
            "Epoch 72/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6478 - accuracy: 0.7207 - val_loss: 1.3199 - val_accuracy: 0.5136\n",
            "Epoch 73/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6545 - accuracy: 0.7167 - val_loss: 1.3331 - val_accuracy: 0.4824\n",
            "Epoch 74/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6410 - accuracy: 0.7248 - val_loss: 1.3277 - val_accuracy: 0.4729\n",
            "Epoch 75/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6498 - accuracy: 0.7189 - val_loss: 1.3218 - val_accuracy: 0.4856\n",
            "Epoch 76/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6408 - accuracy: 0.7246 - val_loss: 1.3307 - val_accuracy: 0.4882\n",
            "Epoch 77/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6399 - accuracy: 0.7258 - val_loss: 1.3332 - val_accuracy: 0.4816\n",
            "Epoch 78/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6375 - accuracy: 0.7270 - val_loss: 1.3355 - val_accuracy: 0.4878\n",
            "Epoch 79/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6389 - accuracy: 0.7295 - val_loss: 1.3478 - val_accuracy: 0.4587\n",
            "Epoch 80/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6483 - accuracy: 0.7207 - val_loss: 1.3696 - val_accuracy: 0.4554\n",
            "Epoch 81/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6353 - accuracy: 0.7295 - val_loss: 1.3314 - val_accuracy: 0.4936\n",
            "Epoch 82/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6346 - accuracy: 0.7290 - val_loss: 1.3495 - val_accuracy: 0.5064\n",
            "Epoch 83/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6314 - accuracy: 0.7317 - val_loss: 1.3768 - val_accuracy: 0.4907\n",
            "Epoch 84/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6353 - accuracy: 0.7275 - val_loss: 1.3628 - val_accuracy: 0.4645\n",
            "Epoch 85/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6345 - accuracy: 0.7242 - val_loss: 1.3566 - val_accuracy: 0.4602\n",
            "Epoch 86/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6382 - accuracy: 0.7269 - val_loss: 1.3429 - val_accuracy: 0.4911\n",
            "Epoch 87/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6371 - accuracy: 0.7263 - val_loss: 1.3564 - val_accuracy: 0.4787\n",
            "Epoch 88/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6302 - accuracy: 0.7306 - val_loss: 1.3668 - val_accuracy: 0.5089\n",
            "Epoch 89/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6258 - accuracy: 0.7322 - val_loss: 1.3584 - val_accuracy: 0.4754\n",
            "Epoch 90/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.7347 - val_loss: 1.3694 - val_accuracy: 0.4773\n",
            "Epoch 91/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6291 - accuracy: 0.7302 - val_loss: 1.3797 - val_accuracy: 0.4671\n",
            "Epoch 92/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6260 - accuracy: 0.7351 - val_loss: 1.3726 - val_accuracy: 0.4769\n",
            "Epoch 93/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6305 - accuracy: 0.7310 - val_loss: 1.3711 - val_accuracy: 0.5071\n",
            "Epoch 94/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6298 - accuracy: 0.7313 - val_loss: 1.3689 - val_accuracy: 0.4987\n",
            "Epoch 95/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6246 - accuracy: 0.7329 - val_loss: 1.3610 - val_accuracy: 0.4947\n",
            "Epoch 96/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6230 - accuracy: 0.7362 - val_loss: 1.3740 - val_accuracy: 0.4900\n",
            "Epoch 97/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6237 - accuracy: 0.7361 - val_loss: 1.3655 - val_accuracy: 0.4660\n",
            "Epoch 98/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6258 - accuracy: 0.7286 - val_loss: 1.3844 - val_accuracy: 0.4525\n",
            "Epoch 99/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6271 - accuracy: 0.7319 - val_loss: 1.3769 - val_accuracy: 0.4995\n",
            "Epoch 100/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6202 - accuracy: 0.7368 - val_loss: 1.3949 - val_accuracy: 0.5005\n",
            "Epoch 101/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6281 - accuracy: 0.7298 - val_loss: 1.3923 - val_accuracy: 0.4955\n",
            "Epoch 102/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6195 - accuracy: 0.7356 - val_loss: 1.4052 - val_accuracy: 0.5020\n",
            "Epoch 103/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6154 - accuracy: 0.7346 - val_loss: 1.3976 - val_accuracy: 0.4991\n",
            "Epoch 104/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.7392 - val_loss: 1.4052 - val_accuracy: 0.5002\n",
            "Epoch 105/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6156 - accuracy: 0.7360 - val_loss: 1.3933 - val_accuracy: 0.5158\n",
            "Epoch 106/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6211 - accuracy: 0.7373 - val_loss: 1.4118 - val_accuracy: 0.5071\n",
            "Epoch 107/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6091 - accuracy: 0.7386 - val_loss: 1.4007 - val_accuracy: 0.5067\n",
            "Epoch 108/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6155 - accuracy: 0.7384 - val_loss: 1.3925 - val_accuracy: 0.4794\n",
            "Epoch 109/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6155 - accuracy: 0.7371 - val_loss: 1.4188 - val_accuracy: 0.4838\n",
            "Epoch 110/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6123 - accuracy: 0.7392 - val_loss: 1.4181 - val_accuracy: 0.4784\n",
            "Epoch 111/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6200 - accuracy: 0.7313 - val_loss: 1.3947 - val_accuracy: 0.4871\n",
            "Epoch 112/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6069 - accuracy: 0.7431 - val_loss: 1.4030 - val_accuracy: 0.4660\n",
            "Epoch 113/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6074 - accuracy: 0.7418 - val_loss: 1.4163 - val_accuracy: 0.4685\n",
            "Epoch 114/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6062 - accuracy: 0.7431 - val_loss: 1.4060 - val_accuracy: 0.4754\n",
            "Epoch 115/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6091 - accuracy: 0.7390 - val_loss: 1.4179 - val_accuracy: 0.4878\n",
            "Epoch 116/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6089 - accuracy: 0.7398 - val_loss: 1.4101 - val_accuracy: 0.4714\n",
            "Epoch 117/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6107 - accuracy: 0.7385 - val_loss: 1.4199 - val_accuracy: 0.4653\n",
            "Epoch 118/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.7446 - val_loss: 1.4099 - val_accuracy: 0.4824\n",
            "Epoch 119/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6068 - accuracy: 0.7398 - val_loss: 1.4223 - val_accuracy: 0.4725\n",
            "Epoch 120/120\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.6036 - accuracy: 0.7419 - val_loss: 1.3935 - val_accuracy: 0.4965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2Zg7uEQl37G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a507b481-da64-4c70-edc2-e9049a361565"
      },
      "source": [
        "pred_valid = model.predict(X_valid)\r\n",
        "pred_valid = np.argmax(pred_valid, axis=-1)\r\n",
        "f1_score(y_valid, pred_valid, average='macro')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34901812599422083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reE6AScphGQi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "77541fc1-7c83-4d59-d598-637805e3cb67"
      },
      "source": [
        "out = pd.read_csv(\"/content/Hotel-A-test.csv\")\r\n",
        "out = pd.DataFrame(out['Reservation-id'])\r\n",
        "out['Reservation_status'] = np.argmax(model.predict(X_test), axis=-1)+1\r\n",
        "out.to_csv('submit.csv', index=False)      \r\n",
        "files.download('submit.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_637d01d6-5678-42c2-8ed6-9a09b1f02841\", \"submit.csv\", 47066)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R8qqI4_-VsP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}